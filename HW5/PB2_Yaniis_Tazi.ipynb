{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "45 mn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) IBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Frameworks for DL:\n",
    "\n",
    "## TensorFlow Version 1.15 in an Anaconda 2019.03 environment and Version 2.1 with Python 3.7\n",
    "\n",
    "## Keras 2.2.5 with TensorFlow 1.15 in an Anaconda 2019.03 environment\n",
    "\n",
    "## PyTorch Versions: 1.2 (deployment) 1.1, 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Compute units for DL\n",
    "## k80\n",
    "## k80x2\n",
    "## k80x4\n",
    "## v100\n",
    "## v100x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model life cycle management for DL\n",
    "\n",
    "## IBM's implementation uses Marathon cluster management system and Apache Zookeeper\n",
    "\n",
    "## Different tasks :\n",
    "\n",
    "## (1) push training job using the Mesos/Marathon cluster management system \n",
    "\n",
    "## (2) Checks whether the parameter server and learners have started successfully \n",
    "\n",
    "## (3) Monitoring of status of the learners at runtime and reports their status to all other components \n",
    "\n",
    "## (4) Detects failures and ensures that failed components are restarted by the cluster so that the process is never interrupted\n",
    "\n",
    "## (5)Monitors end for an optimal ressource allocation finished so that the training job can be safely terminated and resources allocated to it be reclaimed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Monitoring for DL\n",
    "\n",
    "## ELK Stack collects all the logs produced , all the training jobs and enables users to view the logs of their training jobs for debugging purposes.\n",
    "\n",
    "## How to monitor a DL job :  use the cli command bx ml experiments <experiment-ID> <experiment-run-ID>\n",
    "\n",
    "## bx ml monitor experiments c2e94a92-cefe-45b7-bc99-56420abcaa1a 0478fd57-887f-4e38-9068-a09fcc7c688d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Visualization during training for DL :\n",
    "\n",
    "## DLaaS provides user with a real-time visualization component, making it easy for the user to interact and monitor performances of long-training jobs.\n",
    "    \n",
    "## (1)  API  streaming raw logs over a websocket connection\n",
    "\n",
    "## (2) Extensible log parsing API and service, which parses one or more log streams into a common JSON list format. (\n",
    "    \n",
    "## (3) Parsed logs are sent to a visualization server\n",
    "    \n",
    "## (4) Visualization is dynamic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Elastic Scaling for DL :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Deep Learning capabilities from IBM WatsonÂ® Machine Learning Accelerator have been developed for large-scale distributed deep learning workloads. The goal is to transfoorm static training into a  dynamic process robust to failures that can automatically scales GPU allocation during training process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Training job description for DL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Frameworks for DL:\n",
    "\n",
    "## TensorFlow Enterprise 2.x\n",
    "\n",
    "## TensorFlow Enterprise 1.x\n",
    "\n",
    "## TensorFlow 2.x\n",
    "\n",
    "## TensorFlow 1.x\n",
    "\n",
    "## PyTorch\n",
    "\n",
    "## others like Caffe are only experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Compute units for DL\n",
    "\n",
    "## T4 (1,2,4)\n",
    "\n",
    "## P4 (1,2,4)\n",
    "\n",
    "## V100 (1,2,4,8)\n",
    "\n",
    "## P100 (1,2,4)\n",
    "\n",
    "## K80 (1,2,4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model life cycle management for DL\n",
    "\n",
    "## It is an end-to-end ML life cycle :\n",
    "\n",
    "## (1)Prepare and store your datasets with BigQuery and Cloud Storage, use Data Labeling Service to label training data \n",
    "\n",
    "## (2)Build  ML models without writing any code with AutoML's UI or write own code in Notebooks\n",
    "\n",
    "## (3)Validate model with AI Explanations and What-If Tool for hyperparameter optimization and performance.\n",
    "\n",
    "## (4)Deploy models at scale to get predictions in the cloud with Prediction\n",
    "\n",
    "## (1)Manage  models, experiments, and end-to-end workflows with Pipelines by applying MLOps \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Monitoring for DL\n",
    "\n",
    "## AI Platform Training Jobs:\n",
    "\n",
    "## (1) Find your job in the list.\n",
    "\n",
    "## (2) Click your job name in the list to open the Job Details page.\n",
    "\n",
    "## (3) Select the tabs labeled CPU, GPU, or Network to view the associated resource utilization charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Visualization during training for DL :\n",
    "\n",
    "## Configure  training application and save training symmary data to  visualize with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Elastic Scaling for DL :\n",
    "\n",
    "## They offer Managed instance groups (MIGs) for autoscaling allowing us to add or delete virtual machine (VM) instances from a MIG based on increases or decreases in load. It helps for  handling increase traffic and reduce costs when less ressources are needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Training job description for DL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Microsoft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Frameworks for DL:\n",
    "\n",
    "## Caffe\n",
    "\n",
    "## Caffe2\n",
    "\n",
    "## Chainer\n",
    "\n",
    "## Keras\n",
    "\n",
    "## CNTK\n",
    "\n",
    "## MXNet\n",
    "\n",
    "## PyTorch\n",
    "\n",
    "## TensorFlow\n",
    "\n",
    "## Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Compute units for DL\n",
    "\n",
    "## K80\n",
    "## P40\n",
    "## P100\n",
    "## V100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model life cycle management for DL\n",
    "\n",
    "## MLOps based on DevOps for model management,deployment  and monitoring ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Monitoring for DL\n",
    "\n",
    "## Azure Monitor : full stack monitoring service providing a complete set of features to monitor the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Visualization during training for DL :\n",
    "\n",
    "## Evaluate Model module in Azure NL to get accuracy and other evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Elastic Scaling for DL :\n",
    "\n",
    "## Azure Autoscale : built-in feature to make the most out of the resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Training job description for DL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV) Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Frameworks for DL:\n",
    "\n",
    "## MXNet\n",
    "\n",
    "## Chainer\n",
    "\n",
    "## PyTorch\n",
    "\n",
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Compute units for DL\n",
    "\n",
    "## Amazon EC2 P3 Instances have up to 8 NVIDIA Tesla V100 GPU\n",
    "\n",
    "## Amazon EC2 P2 Instances have up to 16 NVIDIA NVIDIA K80 GPUs\n",
    "\n",
    "## Amazon EC2 G3 Instances have up to 4 NVIDIA Tesla M60 GPUs\n",
    "\n",
    "## Amazon EC2 G4 Instances have up to 4 NVIDIA T4 GPUs\n",
    "\n",
    "## Amazon EC2 P4 Instances have up to 8 NVIDIA Tesla A100 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Model life cycle management for DL\n",
    "\n",
    "## SageMaker platforms with dozen of tools readily available and providing ability to build,train,tune and deploy ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Monitoring for DL\n",
    "\n",
    "## Amazon  CloudWatch Logs to  monitor,store and  access log  files ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Visualization during training for DL :\n",
    "\n",
    "## Amazon SageMaker provide training job details and Metric section to find all metrics published by training algorithm on the Amazon CloudWatch Logs and Amaxon CloudWatch Metrics streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Elastic Scaling for DL :\n",
    "\n",
    "## Auto Scaling ,Elastic load balancing and Predictive Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Training job description for DL :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
